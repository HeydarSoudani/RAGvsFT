{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wikipedia-api\n",
    "%pip install lmqg\n",
    "%pip install transformers datasets evaluate -q\n",
    "%pip install accelerate -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papare documents\n",
    "    Output: wikiapi_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python doc_preparation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- RAG-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1 Retrieval model: \n",
    "    Input: A list of questions\n",
    "    Output: Top-K relevant documents for each question\n",
    "        File 1: bm25_results.jsonl\n",
    "        File 2: contriever_results.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python retrieval_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2 Answer generator, by In-context learning\n",
    "    Input: A list of questions, Top-K relevant documents for each question (optional)\n",
    "    Output: An answer for each question, accuracy score\n",
    "        File: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python icl_rg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- FT-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1 Question-Answer pairs Generator (QAG)\n",
    "    Input: A list of documents, each one is relevant to each keyword\n",
    "        File: wikiapi_results.json, from doc_preparation.py\n",
    "    Output: A set of QA pairs for each keyword (entity)\n",
    "        File: qag_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python qag.py\n",
    "!python masked_dataset_gen.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2 Answer generator (extractor), by Fine-tuning\n",
    "    Input: A set of QA pairs\n",
    "    Output: An answer for each question, accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python answer_generator_ft.py\n",
    "!python answer_extractor_ft.py\n",
    "!python masked_ft.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PopQA inference\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
